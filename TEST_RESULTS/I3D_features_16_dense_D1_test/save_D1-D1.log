Feature Extraction
Running with parameters: 
  action: save
  name: I3D_features_16_dense
  modality: ['RGB']
  total_batch: 128
  batch_size: 32
  gpus: None
  wandb_name: None
  resume_from: None
  logname: save_D1-D1.log
  models_dir: saved_models/I3D_features_16_dense/Feb07_12-03-21
  train:
    num_iter: 5000
    lr_steps: 3000
    eval_freq: 50
    num_clips: 1
    dense_sampling:
      RGB: True
    num_frames_per_clip:
      RGB: 16
  test:
    num_clips: 5
    dense_sampling:
      RGB: True
    num_frames_per_clip:
      RGB: 16
  dataset:
    annotations_path: train_val
    shift: D1-D1
    workers: 4
    stride: 2
    resolution: 224
    RGB:
      data_path: ../ek_data/frames
      tmpl: img_{:010d}.jpg
      features_name: test_feat_kinetics
    Event:
      rgb4e: 6
  models:
    RGB:
      model: I3D
      normalize: False
      kwargs:
      lr_steps: 3000
      lr: 0.01
      sgd_momentum: 0.9
      weight_decay: 1e-07
      dropout: 0.5
      resolution: 224
      weight_i3d_rgb: ./pretrained_i3d/rgb_imagenet.pt
  split: test
  save:
    num_clips: 5
    dense_sampling:
      RGB: True
    num_frames_per_clip:
      RGB: 16
  config: configs/I3D_save_feat.yaml
  experiment_dir: I3D_features_16_dense/Feb07_12-03-21
  log_dir: TEST_RESULTS/I3D_features_16_dense
  logfile: TEST_RESULTS/I3D_features_16_dense/save_D1-D1.log
Instantiating models per modality
I3D Net	Modality: RGB
Loading Kinetics weights I3D
 * Skipping Logits weight for 'logits.conv3d.weight'
 * Skipping Logits weight for 'logits.conv3d.bias'
Dataloader for D1-test with 435 samples generated
[87/435] top1= 11.494% top5 = 60.920%
[174/435] top1= 11.494% top5 = 58.621%
[261/435] top1= 10.728% top5 = 59.770%
[348/435] top1= 11.207% top5 = 60.632%
[435/435] top1= 10.805% top5 = 61.839%
Final accuracy: top1 = 10.80%	top5 = 61.84%
Class 0 = [33/124] = 26.61%
Class 1 = [0/104] = 0.00%
Class 2 = [6/52] = 11.54%
Class 3 = [0/34] = 0.00%
Class 4 = [0/66] = 0.00%
Class 5 = [0/13] = 0.00%
Class 6 = [1/20] = 5.00%
Class 7 = [7/22] = 31.82%
Accuracy by averaging class accuracies (same weight for each class): 9.371193322806224%
